{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OvSql9uTAwn"
      },
      "source": [
        "# Import thư viện"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3jWjj3SPTX0u"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install librosa            # for augmentation\n",
        "!pip install jiwer              # for calculate wer\n",
        "!pip install tensorflow-io\n",
        "!pip install sentencepiece      # for subword\n",
        "!pip install tensorflow-text==2.8.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvz8wH561Pj1",
        "outputId": "737cb0a3-6899-4216-a925-087e1f7d2001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Hsf7fx0TCI5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow_io as tfio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm.notebook import tqdm\n",
        "from jiwer import wer\n",
        "# import audiomentations as aud\n",
        "import sentencepiece as spm\n",
        "import tensorflow_text as tftext\n",
        "\n",
        "from IPython import display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXWv9TJUF8Pc",
        "outputId": "325f1e5d-8396-4a61-8374-100a12ac923e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.2\n",
            "2.8.2\n"
          ]
        }
      ],
      "source": [
        "print(tf.__version__)\n",
        "print(tftext.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWVXmfIkbmux"
      },
      "source": [
        "# Create dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "BGxOPJOYbjoY"
      },
      "outputs": [],
      "source": [
        "id2label = {\n",
        "    '0' : 'xoay ghế trái',\n",
        "    '1' : 'xoay ghế phải',\n",
        "    '2' : 'bật đèn',\n",
        "    '3' : 'bật đèn lên',\n",
        "    '4' : 'tắt đèn',\n",
        "    '5' : 'tắt đèn đi',\n",
        "    '6' : 'sáng quá',\n",
        "    '7' : 'tối quá',\n",
        "    '8' : 'bật nhạc',\n",
        "    '9' : 'bật nhạc lên',\n",
        "    '10': 'dừng nhạc',\n",
        "    '11': 'chuyển nhạc',\n",
        "    '12': 'bật màn hình',\n",
        "    '13': 'tắt màn hình',\n",
        "    '14': 'bật laptop',\n",
        "    '15': 'tắt laptop',\n",
        "    '16': 'bật tv',\n",
        "    '17': 'tắt tv',\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "78vUFS4Wb22Y"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = '/content/drive/MyDrive/speech_processing/'\n",
        "dataset_paths = [\n",
        "    ROOT_PATH + 'dataset/Thanh_clean', \n",
        "    ROOT_PATH + 'dataset/Ha_clean',\n",
        "    # ROOT_PATH + 'dataset/Hang',\n",
        "    # ROOT_PATH + 'dataset/Hoang',\n",
        "    # ROOT_PATH + 'dataset/Hoang_addition',\n",
        "    # ROOT_PATH + 'dataset/Hung',\n",
        "    # ROOT_PATH + 'dataset/Hung_clean',\n",
        "    ROOT_PATH + 'dataset/Hoang_clean'\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsIlFoJ-hP4d",
        "outputId": "f8f727ca-3fd1-4fee-ca73-5ec1c859557b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of commands: 18\n",
            "Commands: ['6', '4', '9', '0', '8', '1', '7', '5', '2', '3', '12', '10', '11', '13', '14', '15', '16', '17']\n"
          ]
        }
      ],
      "source": [
        "classes = os.listdir(dataset_paths[0])\n",
        "print('Total number of commands:', len(classes))\n",
        "print('Commands:', classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "960db0c6085b4c45b16d33769feff741",
            "5ccc1185d7eb4ada8545c9fd8231a43e",
            "ea204d16d84446a5bbae9f4c22c1e638",
            "79b68f60d61f435c82ecaa9c16165f0f",
            "edeca3e11dd64f9da8115dca6aff2734",
            "0835041fd07b414ab3bc75cb54326249",
            "5d5cdc7a68cf4453bebde91ad27d13f6",
            "7417a5d1b5b34079a5e9450d3c91af5b",
            "5b4518104b014f6d9f9dfa3f76245bff",
            "ec93e77a73964bf0868ae27527270cc8",
            "9878baec5a81463ab7d0fa0f259a41be"
          ]
        },
        "id": "Hci3CLouhbX-",
        "outputId": "7e09ceaf-df73-49d7-d5e3-d3dcb16f93b7"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "960db0c6085b4c45b16d33769feff741"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Create dataframe's data\n",
        "data_input = {\n",
        "    'filepath': [],\n",
        "    'transcription': []\n",
        "}\n",
        "\n",
        "for path in tqdm(dataset_paths):\n",
        "    for com in classes:\n",
        "        wavdir = os.path.join(path, com)\n",
        "        wavpaths = [os.path.join(wavdir, filepath) for filepath in os.listdir(wavdir) if filepath.endswith('.wav')]\n",
        "        data_input['filepath'].extend(wavpaths)\n",
        "        data_input['transcription'].extend([id2label[com]] * len(wavpaths))\n",
        "\n",
        "# Create df\n",
        "df = pd.DataFrame.from_dict(data_input)\n",
        "df.sort_values(by='transcription', inplace=True, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FxWrjACwj5NQ",
        "outputId": "90e750e3-955d-48df-be47-ba6ef8ce2971"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               filepath  transcription\n",
              "0     /content/drive/MyDrive/speech_processing/datas...     bật laptop\n",
              "1     /content/drive/MyDrive/speech_processing/datas...     bật laptop\n",
              "2     /content/drive/MyDrive/speech_processing/datas...     bật laptop\n",
              "3     /content/drive/MyDrive/speech_processing/datas...     bật laptop\n",
              "4     /content/drive/MyDrive/speech_processing/datas...     bật laptop\n",
              "...                                                 ...            ...\n",
              "2983  /content/drive/MyDrive/speech_processing/datas...  xoay ghế trái\n",
              "2984  /content/drive/MyDrive/speech_processing/datas...  xoay ghế trái\n",
              "2985  /content/drive/MyDrive/speech_processing/datas...  xoay ghế trái\n",
              "2986  /content/drive/MyDrive/speech_processing/datas...  xoay ghế trái\n",
              "2987  /content/drive/MyDrive/speech_processing/datas...  xoay ghế trái\n",
              "\n",
              "[2988 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c9a42db-8594-4e82-8d70-345016884f09\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2983</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>xoay ghế trái</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2984</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>xoay ghế trái</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2985</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>xoay ghế trái</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2986</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>xoay ghế trái</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2987</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>xoay ghế trái</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2988 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c9a42db-8594-4e82-8d70-345016884f09')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c9a42db-8594-4e82-8d70-345016884f09 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c9a42db-8594-4e82-8d70-345016884f09');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svbIifdFyzGn"
      },
      "source": [
        "# Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QeJlTSJqNN3Q"
      },
      "outputs": [],
      "source": [
        "df_labels = {'label': [], 'df': [], 'amount': []}\n",
        "label_counts = df.transcription.value_counts()\n",
        "for label, df_label in df.groupby('transcription'):\n",
        "    df_labels['label'].append(label)\n",
        "    df_labels['df'].append(df_label.sample(frac=1).reset_index(drop=True))\n",
        "    df_labels['amount'].append(label_counts[label])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WVeePXSUikd",
        "outputId": "9d1aba37-1f59-4e8c-b939-708c72707844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training data: 2089\n",
            "Size of validation data: 442\n",
            "Size of test data: 457\n"
          ]
        }
      ],
      "source": [
        "df_train = pd.DataFrame(columns=['filepath', 'transcription'])\n",
        "df_val = pd.DataFrame(columns=['filepath', 'transcription'])\n",
        "df_test = pd.DataFrame(columns=['filepath', 'transcription'])\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.15\n",
        "\n",
        "for idx in range(len(df_labels['df'])):\n",
        "    num_train = int(train_ratio * df_labels['amount'][idx])\n",
        "    num_val = int(val_ratio * df_labels['amount'][idx])\n",
        "    df_label = df_labels['df'][idx]\n",
        "\n",
        "    df_train = pd.concat([df_train, df_label[:num_train]])\n",
        "    df_val = pd.concat([df_val, df_label[num_train:(num_train + num_val)]])\n",
        "    df_test = pd.concat([df_test, df_label[(num_train + num_val):]])\n",
        "\n",
        "df_train = df_train.sample(frac=1).reset_index(drop=True)\n",
        "df_val = df_val.sample(frac=1).reset_index(drop=True)\n",
        "df_test = df_test.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "\n",
        "print('Size of training data:', len(df_train))\n",
        "print('Size of validation data:', len(df_val))\n",
        "print('Size of test data:', len(df_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "16qBfLk36ESu",
        "outputId": "94af857f-5a31-43aa-c9dd-17e1ba8e7eac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               filepath  transcription\n",
              "0     /content/drive/MyDrive/speech_processing/datas...         bật tv\n",
              "1     /content/drive/MyDrive/speech_processing/datas...   tắt màn hình\n",
              "2     /content/drive/MyDrive/speech_processing/datas...        bật đèn\n",
              "3     /content/drive/MyDrive/speech_processing/datas...   bật nhạc lên\n",
              "4     /content/drive/MyDrive/speech_processing/datas...  xoay ghế trái\n",
              "...                                                 ...            ...\n",
              "2084  /content/drive/MyDrive/speech_processing/datas...     tắt đèn đi\n",
              "2085  /content/drive/MyDrive/speech_processing/datas...    bật đèn lên\n",
              "2086  /content/drive/MyDrive/speech_processing/datas...   bật màn hình\n",
              "2087  /content/drive/MyDrive/speech_processing/datas...     bật laptop\n",
              "2088  /content/drive/MyDrive/speech_processing/datas...         bật tv\n",
              "\n",
              "[2089 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-710cfcae-cac2-4ef5-9098-73a3ef4eaaec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filepath</th>\n",
              "      <th>transcription</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật tv</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>tắt màn hình</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật đèn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật nhạc lên</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>xoay ghế trái</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2084</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>tắt đèn đi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2085</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật đèn lên</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2086</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật màn hình</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2087</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật laptop</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2088</th>\n",
              "      <td>/content/drive/MyDrive/speech_processing/datas...</td>\n",
              "      <td>bật tv</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2089 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-710cfcae-cac2-4ef5-9098-73a3ef4eaaec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-710cfcae-cac2-4ef5-9098-73a3ef4eaaec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-710cfcae-cac2-4ef5-9098-73a3ef4eaaec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DY2n2q-6As9"
      },
      "source": [
        "# Create vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4enePZTOsAIu"
      },
      "outputs": [],
      "source": [
        "corpus_set = []\n",
        "corpus_path = ROOT_PATH + 'corpus.txt'\n",
        "\n",
        "for transcript, cnt in df.transcription.value_counts().iteritems():\n",
        "    corpus = [transcript + '\\n'] * cnt\n",
        "    corpus_set.extend(corpus)\n",
        "\n",
        "with open(corpus_path, 'w') as f:\n",
        "    f.writelines(corpus_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "F57Lwd-Kxwn8"
      },
      "outputs": [],
      "source": [
        "# Some constants\n",
        "vocab_size = 54\n",
        "unk_id = 1\n",
        "pad_id = 0\n",
        "model_prefix = ROOT_PATH + f'vocab/subword_{vocab_size}'\n",
        "model_path = model_prefix + '.model'\n",
        "\n",
        "\n",
        "if not os.path.isfile(model_path) and corpus_path:\n",
        "    spm.SentencePieceTrainer.train(\n",
        "        input=corpus_path,\n",
        "        model_prefix=model_prefix,\n",
        "        vocab_size=vocab_size,\n",
        "        character_coverage=0.9995,\n",
        "        model_type='bpe',\n",
        "        num_threads=4,\n",
        "        unk_id=unk_id,\n",
        "        bos_id=-1,\n",
        "        eos_id=-1,\n",
        "        pad_id=pad_id,\n",
        "        unk_piece='<unk>',\n",
        "        bos_piece='<s>',\n",
        "        eos_piece='<\\s>',\n",
        "        pad_piece='<blank>',\n",
        "        user_defined_symbols=''\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "xhWA6jgg8NC1"
      },
      "outputs": [],
      "source": [
        "with open(model_path, 'rb') as f:\n",
        "    model = f.read()\n",
        "\n",
        "tokenizer = tftext.SentencepieceTokenizer(\n",
        "    model=model, out_type=tf.int32, nbest_size=0, \n",
        "    add_bos=False, add_eos=False, return_nbest=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dexsRi7iR1jP",
        "outputId": "ca34862e-2603-4ddb-95ac-f55166c773b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xoay ghế trái'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "a = tokenizer.tokenize('xoay ghế trái')\n",
        "tokenizer.detokenize(a).numpy().decode('utf-8')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fViLbA8TZEWJ"
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhjAWf-3a4FL"
      },
      "source": [
        "## Trích xuất đặc trưng\n",
        "Ở đây dùng mel log spectrogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Qtgy3x9UXh-R"
      },
      "outputs": [],
      "source": [
        "num_mel_bins = 80\n",
        "\n",
        "def extract_log_mel_spectrogram(waveform, sr=16000):\n",
        "    # ((frames - frame_length) // frame_step + 1, fft_length // 2 + 1)\n",
        "    stfts = tf.signal.stft(waveform, frame_length=1024, frame_step=256, fft_length=1024)\n",
        "    spectrograms = tf.abs(stfts)\n",
        "    num_spectrogram_bins = tf.shape(spectrograms)[-1]\n",
        "    lower_edge_hertz, upper_edge_hertz, num_mel_bins = 0.0, 8000.0, 80\n",
        "    # (num_spectrogram_bins, num_mel_bins)\n",
        "    linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n",
        "        num_mel_bins,\n",
        "        num_spectrogram_bins,\n",
        "        sample_rate=sr,\n",
        "        lower_edge_hertz=lower_edge_hertz,\n",
        "        upper_edge_hertz=upper_edge_hertz\n",
        "    )\n",
        "    # ((frames - frame_length) // frame_step + 1, num_mel_bins)\n",
        "    mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n",
        "    mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n",
        "\n",
        "    log_mel_spectrogram = tf.math.log(mel_spectrograms + 1e-6)\n",
        "    # mfcc = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrogram)\n",
        "    return log_mel_spectrogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9hs2mgcwbb21"
      },
      "source": [
        "## Augment data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "CVOFcuOqZfNm"
      },
      "outputs": [],
      "source": [
        "from librosa.effects import pitch_shift, time_stretch\n",
        "\n",
        "def pitch_shift_tf(waveform, sr, n_steps):\n",
        "    return pitch_shift(waveform, sr=sr, n_steps=n_steps)\n",
        "\n",
        "def time_stretch_tf(waveform, rate):\n",
        "    return time_stretch(waveform, rate=rate)\n",
        "\n",
        "def augment(audio, augment_type, prob_threshold=0.6):\n",
        "    if 'gain' in augment_type:\n",
        "        prob = tf.random.uniform(shape=())\n",
        "        gain = tf.random.uniform(shape=(), minval=8, maxval=11, dtype=tf.float32)\n",
        "        augmented = audio * 10 ** (gain / 20.0)\n",
        "        audio = tf.cond(prob < prob_threshold, lambda: augmented, lambda: audio)\n",
        "    \n",
        "    if 'time_mask' in augment_type:\n",
        "        # time_mask_ratio = 0.02\n",
        "        # time_mask_para = tf.cast(tf.cast(tf.shape(audio)[0], dtype=tf.float32) * time_mask_ratio, dtype=tf.int32)\n",
        "        time_mask_para = 10\n",
        "        time_mask_num = 2\n",
        "        prob = tf.random.uniform(shape=())\n",
        "        if prob < prob_threshold:\n",
        "            for _ in range(time_mask_num):\n",
        "                audio = tfio.audio.time_mask(audio, time_mask_para)\n",
        "\n",
        "    if 'frequency_mask' in augment_type:\n",
        "        freq_mask_para = 27\n",
        "        freq_mask_num = 1\n",
        "        prob = tf.random.uniform(shape=())\n",
        "        if prob < prob_threshold:\n",
        "            for _ in range(freq_mask_num):\n",
        "                audio = tfio.audio.freq_mask(audio, freq_mask_para)\n",
        "\n",
        "    if 'pitch_shift' in augment_type:\n",
        "        # init vars\n",
        "        min_semitones = -4\n",
        "        max_semitones = 4\n",
        "        sample_rate = 16000\n",
        "        num_semitones = tf.random.uniform(shape=(), minval=min_semitones, maxval=max_semitones, dtype=tf.int32)\n",
        "\n",
        "        prob = tf.random.uniform(shape=())\n",
        "        augmented_audio = tf.numpy_function(pitch_shift_tf, [audio, sample_rate, num_semitones], tf.float32)\n",
        "        audio = tf.cond(prob < prob_threshold, lambda: augmented_audio, lambda: audio)\n",
        "\n",
        "    if 'time_stretch' in augment_type:\n",
        "        # init vars\n",
        "        min_speed_rate = 0.9\n",
        "        max_speed_rate = 1.1\n",
        "        sample_rate = 16000\n",
        "\n",
        "        speed_rate = tf.random.uniform(shape=(), minval=min_speed_rate, maxval=max_speed_rate)\n",
        "        prob = tf.random.uniform(shape=())\n",
        "        augmented_audio = tf.numpy_function(time_stretch_tf, [audio, speed_rate], tf.float32)\n",
        "        audio = tf.cond(prob < prob_threshold, lambda: augmented_audio, lambda: audio)\n",
        "\n",
        "    return audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GHeCseXpEY8"
      },
      "source": [
        "## Formatted whole dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kGeiqvc48kLF"
      },
      "outputs": [],
      "source": [
        "def get_shape(inputs: tf.Tensor):\n",
        "    static = inputs.shape.as_list()\n",
        "    dynamic = tf.shape(inputs, out_type=tf.int32)\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lKJIxCon1UAp"
      },
      "outputs": [],
      "source": [
        "def get_formatted_data(filepath, label):\n",
        "    waveform = tf.io.read_file(filepath)\n",
        "    waveform, sr = tf.audio.decode_wav(waveform, desired_channels=1)\n",
        "    waveform = tf.squeeze(waveform, axis=-1)\n",
        "\n",
        "    # Augment audio\n",
        "    augment_types = ['gain', 'pitch_shift', 'time_stretch']\n",
        "    waveform = augment(waveform, augment_types)\n",
        "    # Extract mel\n",
        "    features = extract_log_mel_spectrogram(waveform, sr)\n",
        "    features = tf.ensure_shape(features, [None, num_mel_bins])\n",
        "    # Augment feature\n",
        "    augment_types = ['time_mask', 'frequency_mask']\n",
        "    features = augment(features, augment_types)\n",
        "\n",
        "    # Label processing\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tokenizer.tokenize(label)\n",
        "\n",
        "    return features, label\n",
        "\n",
        "\n",
        "def get_formatted_data_test(filepath, label):\n",
        "    waveform = tf.io.read_file(filepath)\n",
        "    waveform, sr = tf.audio.decode_wav(waveform, desired_channels=1)\n",
        "    waveform = tf.squeeze(waveform, axis=-1)\n",
        "\n",
        "    # Augment audio\n",
        "    augment_types = ['gain']\n",
        "    waveform = augment(waveform, augment_types)\n",
        "    # Extract mel\n",
        "    features = extract_log_mel_spectrogram(waveform, sr)\n",
        "    features = tf.ensure_shape(features, [None, num_mel_bins])\n",
        "    # Augment feature\n",
        "    augment_types = []\n",
        "    features = augment(features, augment_types)\n",
        "    print(tf.shape(features))\n",
        "\n",
        "    # Label processing\n",
        "    label = tf.strings.lower(label)\n",
        "    label = tokenizer.tokenize(label)\n",
        "\n",
        "    return features, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYwRSLVOAAIO",
        "outputId": "88b9f747-0c29-4d80-df8e-720c12cc2ed6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"Shape_1:0\", shape=(2,), dtype=int32)\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "\n",
        "\n",
        "def prepare_dataset(df, map_func, num_repeats=2):\n",
        "    files_ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (list(df['filepath']), list(df['transcription']))\n",
        "    )\n",
        "    repeat_ds = files_ds.repeat(num_repeats)\n",
        "    repeat_ds = repeat_ds.shuffle(batch_size, reshuffle_each_iteration=True)\n",
        "    output_ds = repeat_ds.map(\n",
        "        map_func=map_func,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "    output_ds = output_ds.padded_batch(batch_size, padded_shapes=([None, num_mel_bins], [None]), padding_values=(0.0, 0), drop_remainder=True)\n",
        "    output_ds = output_ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return output_ds\n",
        "\n",
        "\n",
        "train_ds = prepare_dataset(df_train, get_formatted_data)\n",
        "val_ds = prepare_dataset(df_val, get_formatted_data)\n",
        "test_ds = prepare_dataset(df_test, get_formatted_data_test, num_repeats=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbGfPrrUKdht",
        "outputId": "4f6cf18b-63c7-48f4-e887-0af1fa11542e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training data size: 130\n",
            "Total validation data size: 27\n",
            "Total test data size: 14\n"
          ]
        }
      ],
      "source": [
        "print('Total training data size:', train_ds.cardinality().numpy())\n",
        "print('Total validation data size:', val_ds.cardinality().numpy())\n",
        "print('Total test data size:', test_ds.cardinality().numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7D3MsesupKNg"
      },
      "source": [
        "# Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "KHclIqbwo8dL"
      },
      "outputs": [],
      "source": [
        "def CTCLoss(y_true, y_pred):\n",
        "    # Compute the training-time loss value\n",
        "    batch_len = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
        "    input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
        "    label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
        "\n",
        "    input_length = input_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "    label_length = label_length * tf.ones(shape=(batch_len, 1), dtype=\"int64\")\n",
        "\n",
        "    loss = tf.keras.backend.ctc_batch_cost(y_true, y_pred, input_length, label_length)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WPUcby8t22v"
      },
      "source": [
        "# Create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "nyu3yuIpo-4r"
      },
      "outputs": [],
      "source": [
        " def build_model(input_dim, output_dim, rnn_layers=5, rnn_units=128):\n",
        "    \"\"\"Model similar to DeepSpeech2.\"\"\"\n",
        "    # Model's input\n",
        "    input_spectrogram = tf.keras.layers.Input((None, input_dim), batch_size=None, name=\"input\")\n",
        "    # Expand the dimension to use 2D CNN.\n",
        "    x = tf.keras.layers.Reshape((-1, input_dim, 1), name=\"expand_dim\")(input_spectrogram)\n",
        "    # Convolution layer 1\n",
        "    x = tf.keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 41],\n",
        "        strides=[2, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_1\",\n",
        "    )(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=\"conv_1_bn\")(x)\n",
        "    x = tf.keras.layers.ReLU(name=\"conv_1_relu\")(x)\n",
        "    # Convolution layer 2\n",
        "    x = tf.keras.layers.Conv2D(\n",
        "        filters=32,\n",
        "        kernel_size=[11, 21],\n",
        "        strides=[1, 2],\n",
        "        padding=\"same\",\n",
        "        use_bias=False,\n",
        "        name=\"conv_2\",\n",
        "    )(x)\n",
        "    x = tf.keras.layers.BatchNormalization(name=\"conv_2_bn\")(x)\n",
        "    x = tf.keras.layers.ReLU(name=\"conv_2_relu\")(x)\n",
        "    # Reshape the resulted volume to feed the RNNs layers\n",
        "    x = tf.keras.layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
        "    # RNN layers\n",
        "    for i in range(1, rnn_layers + 1):\n",
        "        recurrent = tf.keras.layers.GRU(\n",
        "            units=rnn_units,\n",
        "            activation=\"tanh\",\n",
        "            recurrent_activation=\"sigmoid\",\n",
        "            use_bias=True,\n",
        "            return_sequences=True,\n",
        "            reset_after=True,\n",
        "            name=f\"gru_{i}\",\n",
        "        )\n",
        "        x = tf.keras.layers.Bidirectional(\n",
        "            recurrent, name=f\"bidirectional_{i}\", merge_mode=\"concat\"\n",
        "        )(x)\n",
        "        if i < rnn_layers:\n",
        "            x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
        "    # Dense layer\n",
        "    x = tf.keras.layers.Dense(units=rnn_units * 2, name=\"dense_1\")(x)\n",
        "    x = tf.keras.layers.ReLU(name=\"dense_1_relu\")(x)\n",
        "    x = tf.keras.layers.Dropout(rate=0.5)(x)\n",
        "    # Classification layer\n",
        "    output = tf.keras.layers.Dense(units=output_dim + 1, activation=\"softmax\")(x)\n",
        "    # Model\n",
        "    model = tf.keras.Model(input_spectrogram, output, name=\"DeepSpeech_2\")\n",
        "    # Optimizer\n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "    # Compile the model and return\n",
        "    model.compile(optimizer=opt, loss=CTCLoss)\n",
        "    return model\n",
        "\n",
        "\n",
        "# Get the model\n",
        "model = build_model(\n",
        "    input_dim=num_mel_bins,\n",
        "    output_dim=vocab_size,\n",
        "    rnn_units=128,\n",
        "    rnn_layers=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xxOn5XcfCoUp",
        "outputId": "20a4174f-a4e9-4ad0-9e29-43054ca8c431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"DeepSpeech_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, None, 80)]        0         \n",
            "                                                                 \n",
            " expand_dim (Reshape)        (None, None, 80, 1)       0         \n",
            "                                                                 \n",
            " conv_1 (Conv2D)             (None, None, 40, 32)      14432     \n",
            "                                                                 \n",
            " conv_1_bn (BatchNormalizati  (None, None, 40, 32)     128       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " conv_1_relu (ReLU)          (None, None, 40, 32)      0         \n",
            "                                                                 \n",
            " conv_2 (Conv2D)             (None, None, 20, 32)      236544    \n",
            "                                                                 \n",
            " conv_2_bn (BatchNormalizati  (None, None, 20, 32)     128       \n",
            " on)                                                             \n",
            "                                                                 \n",
            " conv_2_relu (ReLU)          (None, None, 20, 32)      0         \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, None, 640)         0         \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, None, 256)        591360    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, None, 256)         0         \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, None, 256)        296448    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, None, 256)         65792     \n",
            "                                                                 \n",
            " dense_1_relu (ReLU)         (None, None, 256)         0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, None, 256)         0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 55)          14135     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,218,967\n",
            "Trainable params: 1,218,839\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAHS12Vpt6o2"
      },
      "source": [
        "# Decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "oJVJOZDGCrqn"
      },
      "outputs": [],
      "source": [
        "# A utility function to decode the output of the network\n",
        "def decode_batch_predictions(pred, lab=None):\n",
        "    input_len = tf.ones(tf.shape(pred)[0], dtype=tf.int32) * tf.shape(pred)[1]\n",
        "    # Use greedy search. For complex tasks, you can use beam search\n",
        "    # results, _ = tf.nn.ctc_greedy_decoder(pred, lab, blank_index=pad_id)\n",
        "    results = tf.keras.backend.ctc_decode(pred, input_length=input_len, greedy=True)[0][0]\n",
        "    results = tf.nn.relu(results)\n",
        "    # Iterate over the results and get back the text\n",
        "    output_text = []\n",
        "    for result in results:\n",
        "        result = tokenizer.detokenize(tf.cast(result, dtype=tf.int32)).numpy().decode('utf-8')\n",
        "        output_text.append(result)\n",
        "    return output_text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCDXTt0AuTLx"
      },
      "source": [
        "# Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "olDKfEGHuVil"
      },
      "outputs": [],
      "source": [
        "# A callback class to output a few transcriptions during training\n",
        "class CallbackEval(tf.keras.callbacks.Callback):\n",
        "    \"\"\"Displays a batch of outputs after every epoch.\"\"\"\n",
        "\n",
        "    def __init__(self, dataset):\n",
        "        super().__init__()\n",
        "        self.dataset = dataset\n",
        "\n",
        "    def on_epoch_end(self, epoch: int, logs=None):\n",
        "        predictions = []\n",
        "        targets = []\n",
        "        for batch in self.dataset:\n",
        "            X, y = batch\n",
        "            batch_predictions = model.predict(X)\n",
        "            batch_predictions = decode_batch_predictions(batch_predictions)\n",
        "            predictions.extend(batch_predictions)\n",
        "            for label in y:\n",
        "                label = (tokenizer.detokenize(label).numpy().decode('utf-8'))\n",
        "                targets.append(label)\n",
        "        wer_score = wer(targets, predictions)\n",
        "        print(\"-\" * 100)\n",
        "        print(f\"Word Error Rate: {wer_score:.4f}\")\n",
        "        print(\"-\" * 100)\n",
        "        for i in np.random.randint(0, len(predictions), 2):\n",
        "            print(f\"Target    : {targets[i]}\")\n",
        "            print(f\"Prediction: {predictions[i]}\")\n",
        "            print(\"-\" * 100)\n",
        "\n",
        "# Callback function to check transcription on the val set.\n",
        "validation_callback = CallbackEval(val_ds)\n",
        "\n",
        "# Model checkpoint\n",
        "checkpoint_path = ROOT_PATH + '/checkpoints/ckpt-epoch-{epoch:02d}.ckpt'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        "    save_freq='epoch'\n",
        ")\n",
        "\n",
        "# Backup and restore\n",
        "backup_dir = ROOT_PATH + '/backup/'\n",
        "backup_callback = tf.keras.callbacks.BackupAndRestore(backup_dir=backup_dir)\n",
        "\n",
        "callbacks = [validation_callback, checkpoint_callback, backup_callback]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQnQ_FyoRi-m"
      },
      "source": [
        "# Execute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tYLtMI1dDJc5",
        "outputId": "f3362db3-f3dc-4285-c602-1089162f666b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 59/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.7501----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0155\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : xoay ghế phải\n",
            "Prediction: xoay ghế phải\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : bật đèn\n",
            "Prediction: bật đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 610s 4s/step - loss: 1.7501 - val_loss: 1.5808\n",
            "Epoch 60/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.8253----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0311\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : dừng nhạc\n",
            "Prediction: dừng nhạc\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : bật đèn\n",
            "Prediction: tắt đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 256s 2s/step - loss: 1.8253 - val_loss: 1.5309\n",
            "Epoch 61/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 2.0127----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0359\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : sáng quá\n",
            "Prediction: sáng quá\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : bật nhạc lên\n",
            "Prediction: bật nhạc lên\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 253s 2s/step - loss: 2.0127 - val_loss: 1.7105\n",
            "Epoch 62/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.8092----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0272\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt đèn\n",
            "Prediction: tắt đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : bật tv\n",
            "Prediction: bật tv\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 250s 2s/step - loss: 1.8092 - val_loss: 1.6988\n",
            "Epoch 63/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.7211----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0281\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt đèn\n",
            "Prediction: tắt đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : bật đèn\n",
            "Prediction: bật đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 252s 2s/step - loss: 1.7211 - val_loss: 1.5042\n",
            "Epoch 64/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.8648----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0208\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : chuyển nhạc\n",
            "Prediction: chuyển nhạc\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : xoay ghế phải\n",
            "Prediction: xoay ghế phải\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 252s 2s/step - loss: 1.8648 - val_loss: 1.4896\n",
            "Epoch 65/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.7049----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0223\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tối quá\n",
            "Prediction: tối quá\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt đèn\n",
            "Prediction: tắt đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 250s 2s/step - loss: 1.7049 - val_loss: 1.5779\n",
            "Epoch 66/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.7062----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0228\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt màn hình\n",
            "Prediction: tắt màn hình\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : xoay ghế trái\n",
            "Prediction: xoay ghế trái\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 249s 2s/step - loss: 1.7062 - val_loss: 1.3946\n",
            "Epoch 67/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.7913----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0184\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : sáng quá\n",
            "Prediction: sáng quá\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : sáng quá\n",
            "Prediction: sáng quá\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 249s 2s/step - loss: 1.7913 - val_loss: 1.5453\n",
            "Epoch 68/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.6675----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0252\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt tv\n",
            "Prediction: tắt tv\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tối quá\n",
            "Prediction: tối quá\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 249s 2s/step - loss: 1.6675 - val_loss: 1.4506\n",
            "Epoch 69/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.7230----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0330\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt đèn đi\n",
            "Prediction: tắt đèn đi\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : tắt đèn\n",
            "Prediction: tắt đèn\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 245s 2s/step - loss: 1.7230 - val_loss: 1.4721\n",
            "Epoch 70/70\n",
            "130/130 [==============================] - ETA: 0s - loss: 1.5501----------------------------------------------------------------------------------------------------\n",
            "Word Error Rate: 0.0213\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : dừng nhạc\n",
            "Prediction: dừng nhạc\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Target    : sáng quá\n",
            "Prediction: sáng quá\n",
            "----------------------------------------------------------------------------------------------------\n",
            "130/130 [==============================] - 245s 2s/step - loss: 1.5501 - val_loss: 1.4248\n"
          ]
        }
      ],
      "source": [
        "# Define the number of epochs.\n",
        "epochs = 70\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=epochs,\n",
        "    callbacks=callbacks,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "oql0H7zBDdhu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6a577b59-dcab-41d0-b539-dc7196bfe657"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "metrics = history.history\n",
        "plt.plot(history.epoch, metrics['loss'], metrics['val_loss'])\n",
        "plt.legend(['loss', 'val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "kQuRbz8wZXHG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "SmartRoomSimulator.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "960db0c6085b4c45b16d33769feff741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ccc1185d7eb4ada8545c9fd8231a43e",
              "IPY_MODEL_ea204d16d84446a5bbae9f4c22c1e638",
              "IPY_MODEL_79b68f60d61f435c82ecaa9c16165f0f"
            ],
            "layout": "IPY_MODEL_edeca3e11dd64f9da8115dca6aff2734"
          }
        },
        "5ccc1185d7eb4ada8545c9fd8231a43e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0835041fd07b414ab3bc75cb54326249",
            "placeholder": "​",
            "style": "IPY_MODEL_5d5cdc7a68cf4453bebde91ad27d13f6",
            "value": "100%"
          }
        },
        "ea204d16d84446a5bbae9f4c22c1e638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7417a5d1b5b34079a5e9450d3c91af5b",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b4518104b014f6d9f9dfa3f76245bff",
            "value": 3
          }
        },
        "79b68f60d61f435c82ecaa9c16165f0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec93e77a73964bf0868ae27527270cc8",
            "placeholder": "​",
            "style": "IPY_MODEL_9878baec5a81463ab7d0fa0f259a41be",
            "value": " 3/3 [00:21&lt;00:00,  8.25s/it]"
          }
        },
        "edeca3e11dd64f9da8115dca6aff2734": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0835041fd07b414ab3bc75cb54326249": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d5cdc7a68cf4453bebde91ad27d13f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7417a5d1b5b34079a5e9450d3c91af5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b4518104b014f6d9f9dfa3f76245bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec93e77a73964bf0868ae27527270cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9878baec5a81463ab7d0fa0f259a41be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}